{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a013b2",
   "metadata": {},
   "source": [
    "# Natural Language Inference- MultiNLI, QuestionNLI, Sentiment Analysis, Semantic Similarity\n",
    "\n",
    "### Written by: Rodrigo Escandon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ceed1",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "Natural Language Inference models are being displayed to showcase the ability to determine if sentences are similar, if questions are being answered, if sentiments are positive or if texts are located withing a written paragraph.\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "The models that are being used are transformer models from Huggingface, NLTK and SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67c66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51d266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading language library (python -m spacy download en_core_web_sm)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4130a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1240da04",
   "metadata": {},
   "source": [
    "## Multi-NLI - Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b966b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dd57d704cb4a4e877bce16d6eb533b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarah\\anaconda33\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sarah\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81b25ae263644c09db2c08142945b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ce115333f34c80abcd35e5d448a61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19dedfc1dfc4b00b1a8fbd00be67181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1ba40c15e5435ea02a72a0f3778031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'ENTAILMENT', 'score': 0.9883741140365601}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Providing type of task and model\n",
    "#Bringing in a Multi Genre NLI model\n",
    "classifier_m= pipeline(\"text-classification\", model = \"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb7789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'ENTAILMENT', 'score': 0.9913302659988403}]\n",
      "[{'label': 'CONTRADICTION', 'score': 0.9994875192642212}]\n"
     ]
    }
   ],
   "source": [
    "#Evaluating to see if both sentences are similar (Entailment), different (Contradiction) or neutral (Neutral)\n",
    "print(classifier_m(\"Today is a hot day. Today's temperature is hot.\"))\n",
    "print(classifier_m(\"I am very excited for tomorrow's activities. I don't have any plans for tomorrow.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df66154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1851ba1d",
   "metadata": {},
   "source": [
    "## Question-NLI - Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226a98b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a25028fd50648e38f6317d597809611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/771 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e053bf363b448b973b51d10db5ad31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30943fff81b47439d2dd26ab850dfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/268 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5fa35401f04b0d8f1dc5ee0032a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a739ebf8af434288e52617c9da9057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Providing type of task and model\n",
    "#Bringing in a Question NLI model\n",
    "classifier_q= pipeline(\"text-classification\", model = \"cross-encoder/qnli-electra-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1886bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9925422668457031}]\n",
      "[{'label': 'LABEL_0', 'score': 0.000511180202011019}]\n"
     ]
    }
   ],
   "source": [
    "#Evaluating to see if question is answered by second sentence\n",
    "#If question is answered score is around 1 if not is around 0\n",
    "print(classifier_q(\"Did it rain last night? Yes, last night was raining.\"))\n",
    "print(classifier_q(\"What time is it? I am tired.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce16cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c4f0d1",
   "metadata": {},
   "source": [
    "## Sentiment Analysis- Hugginface and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34575416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9ef45c0e7749c88c2cd3a75b89073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bba643cb82479ba127c0dddb9d153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b904c9032a204b858c426555b989de91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4450f189b9f048599e9d4d44f350b573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Providing type of task\n",
    "#Bringing in a Sentiment Analysis model from Huggingface\n",
    "classifier_s = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd33de3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998375177383423}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997040629386902}]\n"
     ]
    }
   ],
   "source": [
    "#Evaluating to see if sentence is positive, negative or neutral\n",
    "print(classifier_s(\"I had such a great day!\"))\n",
    "print(classifier_s(\"I don't feel well.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ff197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in Sentiment Analisys model from NLTK\n",
    "#Might have to download (nltk.download('vader_lexicon'))\n",
    "sent_nltk=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bdfe1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'compound': 0.6588}\n",
      "{'neg': 0.476, 'neu': 0.524, 'pos': 0.0, 'compound': -0.2057}\n"
     ]
    }
   ],
   "source": [
    "#Calculating scores. Compound is the overall score.\n",
    "#Anything above 0 is assumed to be positive\n",
    "print(sent_nltk.polarity_scores(\"I had such a great day!\"))\n",
    "print(sent_nltk.polarity_scores(\"I don't feel well.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76933f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f537b1b",
   "metadata": {},
   "source": [
    "## Semantic Similarity - SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2269c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the matcher with a share vocabulary\n",
    "matcher=Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b4ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building different patterns for word\n",
    "#mulberrybush\n",
    "pattern1=[{\"LOWER\":\"mulberrybush\"}]\n",
    "pattern2=[{\"LOWER\": \"mulberry\"}, {\"IS_PUNCT\": True,'OP':'*'}, {\"LOWER\": \"bush\"}]\n",
    "pattern3=[{\"LOWER\": \"mulberry\"}, {\"IS_UPPER\": True,'OP':'*'}, {\"LOWER\": \"bush\"}]\n",
    "pattern4=[{\"ORTH\": \"mulberry_bush\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e301ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add those different patterns as match rules to the matcher\n",
    "matcher.add('mulberry bush',[pattern1,pattern2,pattern3,pattern4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0271b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created text that will be used\n",
    "doc=nlp('''Here we go round the mulberrybush,\n",
    "The mulberry_bush,\n",
    "The mulberry-bush.\n",
    "Here we go round the MULBERRY BUSH\n",
    "On a cold and frosty morning.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8ec718",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches=matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "669770d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15321705705911178809, 5, 6), (15321705705911178809, 9, 10), (15321705705911178809, 13, 16), (15321705705911178809, 23, 25)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ec6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15321705705911178809 mulberry bush 5 6 mulberrybush,\n",
      "15321705705911178809 mulberry bush 9 10 mulberry_bush,\n",
      "15321705705911178809 mulberry bush 13 16 mulberry-bush.\n",
      "15321705705911178809 mulberry bush 23 25 MULBERRY BUSH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying matches and adding string after\n",
    "for match_id,start,end in found_matches:\n",
    "    string_id=nlp.vocab.strings[match_id]\n",
    "    span=doc[start:end+1]\n",
    "    print(match_id,string_id,start,end,span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259819d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
